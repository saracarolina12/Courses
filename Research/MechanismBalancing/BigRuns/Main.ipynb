{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BetaShF import ShF\n",
    "from BetaShM import ShM \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSample(prefix, sample, fitness, force, moment):\n",
    "    def appendToFile(name, text): \n",
    "        with open(\"./experiments/\"+name, \"a\") as f:\n",
    "            f.write(text + '\\n')\n",
    "    s = \"\"\n",
    "    for x in sample: s += str(x) + \" \"\n",
    "    appendToFile(str(prefix) + \"_Population.txt\", s)\n",
    "    appendToFile(str(prefix) + \"_Fitness.txt\", str(fitness))\n",
    "    appendToFile(str(prefix) + \"_ShForces.txt\", str(force))\n",
    "    appendToFile(str(prefix) + \"_ShMoments.txt\", str(moment))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(s, ShF, ShM, beta): #c is a constant that distributes the weight among the functions.\n",
    "    return beta*ShF(s) + (1-beta)*ShM(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds [[-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]]\n"
     ]
    }
   ],
   "source": [
    "# Bounds for each variable\n",
    "nVar = 5\n",
    "bounds = []\n",
    "for i in range(1,nVar*3+1):\n",
    "    if(i%3==0): bounds.append([0.005,0.04])\n",
    "    else: bounds.append([-0.16, 0.16])\n",
    "bounds = np.array(bounds)\n",
    "print('bounds',bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Descenso de Gradiente con diferenciación finita\n",
    "def Gradient_Descent(X0,f,bounds,MaxIter=1000,alpha=1e-3, args = ()):\n",
    "    eps = 1e-5\n",
    "    def Gradiente(X,f, args = ()):\n",
    "        n = len(X)\n",
    "        G = np.zeros((n),float)\n",
    "        incX = np.zeros((n),float)\n",
    "        for i in range(n):\n",
    "            incX[i] = eps\n",
    "            G[i] = (f(X+incX, *args)-f(X, *args))/eps\n",
    "            incX[i] = 0\n",
    "        return G\n",
    "    def getStepSize(alpha,m,X,P,G,f, args = ()):\n",
    "        c0 = 1e-4\n",
    "        c1 = 2\n",
    "        c2 = 5\n",
    "        c3 = 3\n",
    "        eps = 1e-8\n",
    "        while f(X+alpha*P, *args) > f(X, *args)+c0*np.dot(G,P):\n",
    "            m = 0\n",
    "            alpha = alpha/c1\n",
    "            if alpha<=eps:\n",
    "                break\n",
    "        m += 1\n",
    "        if m>=c2:\n",
    "            m=0\n",
    "            alpha = c3*alpha\n",
    "        return alpha,m\n",
    "\n",
    "    k=0\n",
    "    X = X0\n",
    "    G = Gradiente(X,f, args)\n",
    "    normaGradiente = np.linalg.norm(G)\n",
    "    m = 0\n",
    "    while(k<=MaxIter and normaGradiente>=eps):\n",
    "        G = Gradiente(X0,f, args)\n",
    "        normaGradiente = np.linalg.norm(G)\n",
    "        P = - G / normaGradiente\n",
    "        alpha,m = getStepSize(alpha,m,X,P,G,f, args)\n",
    "        X = X + alpha*P\n",
    "        X = np.clip(X,bounds[:,0],bounds[:,1])\n",
    "        k = k+1\n",
    "        if k%100 == 0:\n",
    "            print(\"\\t\\t#\",k,f(X, *args))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09842577 -0.14817785  0.03179191 -0.08359883 -0.14385944  0.01968124\n",
      "  0.07994792 -0.10568881  0.01791537 -0.12117131  0.09247776  0.00814046\n",
      "  0.11451271 -0.0123489   0.03112376]\n"
     ]
    }
   ],
   "source": [
    "def random_start(bounds):\n",
    "    arr = np.zeros(bounds.shape[0])\n",
    "    for i, tupl in enumerate(bounds):\n",
    "        rand = np.random.uniform(tupl[0], tupl[1])\n",
    "        arr[i] = rand \n",
    "    return arr\n",
    "    \n",
    "print(random_start(bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = 80\n",
    "# n = 4\n",
    "def GD(GD_alph, iter, nRuns):\n",
    "    startTime_GD = str(int(time.time()))\n",
    "    eTime = 0\n",
    "\n",
    "    print(f'\\n* Number of iterations: {iter}')\n",
    "    for i in range(nRuns):\n",
    "        r = random_start(bounds)\n",
    "        beta = np.random.normal(0.5, 0.20)\n",
    "        fitness = objective_function(r, ShF, ShM, beta)\n",
    "\n",
    "        print(f\"\\t\\nInitial Fitness: {fitness} in #{i}\")\n",
    "        start = time.perf_counter()\n",
    "        r = Gradient_Descent(r,objective_function, bounds,MaxIter=iter, alpha=GD_alph, args=(ShF, ShM, beta))\n",
    "        end = time.perf_counter()\n",
    "        fit_GD = objective_function(r,ShF,ShM, beta)\n",
    "        print(\"\\t  - before: \", fitness)\n",
    "        print(\"\\t  - after (GD): \", fit_GD)\n",
    "        eTime += (end-start) #Time in seconds\n",
    "        shF, shM = ShF(r), ShM(r)\n",
    "        if shF < 1 and shM < 1:\n",
    "            logSample(startTime_GD, r, fit_GD, shF, shM) # (now, sample, fitness, force, moment):\n",
    "    if nRuns: eTime /= nRuns\n",
    "    print(\"Average time of execution:\", eTime,\"seconds. It was run\", nRuns, \"times.\")\n",
    "    # return fit_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 1000\n",
    "nRuns = 100\n",
    "step_size = 6e-4 # Probamos con diferentes step_size, este valor ha sido la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Number of iterations: 1000\n",
      "\t\n",
      "Initial Fitness: 31.698880993919786 in #0\n",
      "\t\t# 100 3.8861230149945962\n",
      "\t\t# 200 3.8861230149945962\n"
     ]
    }
   ],
   "source": [
    "GD(step_size, it, nRuns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
