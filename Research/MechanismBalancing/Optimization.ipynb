{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six-bar Mechanism Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BetaShF import ShF\n",
    "from BetaShM import ShM \n",
    "import numpy as np \n",
    "from scipy.optimize import differential_evolution, minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from cnsg_differential_evolution import cnsg_differential_evolution\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(samples, fitness, forces, moments):\n",
    "    filterF = forces < 1\n",
    "    filterM = moments < 1\n",
    "    f = np.logical_and(filterF, filterM)\n",
    "    print(f.shape)\n",
    "    return samples[f], fitness[f], forces[f], moments[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSample(now, sample, fitness, force, moment):\n",
    "    def appendToFile(name, text): \n",
    "        with open(name, \"a\") as f:\n",
    "            f.write(text + '\\n')\n",
    "    s = \"\"\n",
    "    for x in sample: s += str(x) + \" \"\n",
    "    appendToFile(str(now) + \"_Population.txt\", s)\n",
    "    appendToFile(str(now) + \"_Fitness.txt\", str(fitness))\n",
    "    appendToFile(str(now) + \"_ShForces.txt\", str(force))\n",
    "    appendToFile(str(now) + \"_ShMoments.txt\", str(moment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contraints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$-0.16m <= x_{cn},y_{cn} <= 0.16m$$\n",
    "\n",
    "$$0.005m <= t_{cn} <= 0.04m$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(s, ShF, ShM, a): #c is a constant that distributes the weight among the functions.\n",
    "    return a*ShF(s) + (1-a)*ShM(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds [[-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]\n",
      " [-0.16   0.16 ]\n",
      " [-0.16   0.16 ]\n",
      " [ 0.005  0.04 ]]\n"
     ]
    }
   ],
   "source": [
    "# Bounds for each variable\n",
    "nVar = 5\n",
    "bounds = []\n",
    "for i in range(1,nVar*3+1):\n",
    "    if(i%3==0): bounds.append([0.005,0.04])\n",
    "    else: bounds.append([-0.16, 0.16])\n",
    "bounds = np.array(bounds)\n",
    "print('bounds',bounds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_conjugado(X0,f,MaxIter=100,eps=1e-5):\n",
    "    k=0\n",
    "    X = X0\n",
    "    G = Vf(X,ShF, ShM, f)\n",
    "    normaGradiente = np.linalg.norm(G)\n",
    "    P = -G\n",
    "    curr_fit = f(X,ShF, ShM)\n",
    "    while(k<=MaxIter and normaGradiente>=eps):\n",
    "        Ap = V2fTd(X,ShF, ShM,P,f)\n",
    "        alpha = np.dot(-P,G) / np.dot(P,Ap)\n",
    "        X = X + alpha*P\n",
    "        G_ = np.copy(G)\n",
    "        G = G + alpha*Ap\n",
    "        normaGradiente = np.linalg.norm(G)\n",
    "        B = -np.dot(G,G)/np.dot(G_,G_)\n",
    "        P = -G + B*P\n",
    "        k = k+1\n",
    "        print(\"#\",k, \", fit: \", f(X,ShF, ShM))\n",
    "        if f(X,ShF, ShM) <= curr_fit:\n",
    "            best_x = X\n",
    "            curr_fit = f(best_x,ShF, ShM)\n",
    "    return best_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#################### Descenso de Gradiente con diferenciaciÃ³n finita\n",
    "eps = 1e-5\n",
    "def Gradiente(X,f, ShF, ShM):\n",
    "    n = len(X)\n",
    "    G = np.zeros((n),float)\n",
    "    incX = np.zeros((n),float)\n",
    "    for i in range(n):\n",
    "        incX[i] = eps\n",
    "        G[i] = (f(X+incX, ShF, ShM, a)-f(X, ShF, ShM, a))/eps\n",
    "        incX[i] = 0\n",
    "    return G\n",
    "def getStepSize(a,m,X,P,G,f):\n",
    "    c0 = 1e-4\n",
    "    c1 = 2\n",
    "    c2 = 5\n",
    "    c3 = 3\n",
    "    eps = 1e-8\n",
    "    alpha = a\n",
    "    while f(X+alpha*P, ShF, ShM, a) > f(X, ShF, ShM, a)+c0*np.dot(G,P):\n",
    "        m = 0\n",
    "        alpha = alpha/c1\n",
    "        if alpha<=eps:\n",
    "            break\n",
    "    m += 1\n",
    "    if m>=c2:\n",
    "        m=0\n",
    "        alpha = c3*alpha\n",
    "    return alpha,m\n",
    "\n",
    "def Gradient_Descent(X0,f,bounds,MaxIter=1000,alpha=1e-3):\n",
    "    k=0\n",
    "    X = X0\n",
    "    G = Gradiente(X,f, ShF, ShM)\n",
    "    normaGradiente = np.linalg.norm(G)\n",
    "    m = 0\n",
    "    while(k<=MaxIter and normaGradiente>=eps):\n",
    "        G = Gradiente(X,f, ShF, ShM)\n",
    "        normaGradiente = np.linalg.norm(G)\n",
    "        P = - G / normaGradiente\n",
    "        alpha,m = getStepSize(alpha,m,X,P,G,f)\n",
    "        X = X + alpha*P\n",
    "        X = np.clip(X,bounds[:,0],bounds[:,1])\n",
    "        # verficar bounds: si x() no coincide con sus bounds correspondientes\n",
    "        k = k+1\n",
    "        if k%100 == 0:\n",
    "            print(\"\\t\\t#\",k,f(X, ShF, ShM, a))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OF: 46.604883632565645\n"
     ]
    }
   ],
   "source": [
    "s=bounds[:,0]\n",
    "r = objective_function(s, ShF, ShM,0.5)\n",
    "print('OF:',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01271237 -0.07355877  0.01803034 -0.12579818  0.09111245  0.03189632\n",
      " -0.1226464  -0.05342432  0.01212005  0.11049056 -0.12049435  0.01946655\n",
      " -0.08877147  0.14706508  0.03684394]\n"
     ]
    }
   ],
   "source": [
    "def random_start(bounds):\n",
    "    # print(bounds.shape[0])\n",
    "    arr = np.zeros(bounds.shape[0])\n",
    "    for i, tupl in enumerate(bounds):\n",
    "        rand = np.random.uniform(tupl[0], tupl[1])\n",
    "        # print(i, rand)\n",
    "        arr[i] = rand \n",
    "    return arr\n",
    "    \n",
    "print(random_start(bounds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Number of iterations: 200\n",
      "\t\n",
      "Initial Fitness: 45.84833177270562 in #0\n",
      "\t\t# 100 2.301413761594249\n",
      "\t\t# 200 0.6859729383378889\n",
      "\t  - before:  45.84833177270562\n",
      "\t  - after (GD):  0.825292309582456\n",
      "\t\n",
      "Initial Fitness: 20.677685584951824 in #1\n",
      "\t\t# 100 0.6975940752870484\n",
      "\t\t# 200 0.6975940752744585\n",
      "\t  - before:  20.677685584951824\n",
      "\t  - after (GD):  0.843828478526728\n",
      "\t\n",
      "Initial Fitness: 43.024111300912736 in #2\n",
      "\t\t# 100 1.0765727685799047\n",
      "\t\t# 200 1.0765727685799047\n",
      "\t  - before:  43.024111300912736\n",
      "\t  - after (GD):  1.027028437742662\n",
      "\t\n",
      "Initial Fitness: 25.02425489869586 in #3\n",
      "\t\t# 100 0.7185163221875894\n",
      "\t\t# 200 0.7185163164930441\n",
      "\t  - before:  25.02425489869586\n",
      "\t  - after (GD):  0.8809525282018108\n",
      "\t\n",
      "Initial Fitness: 22.75700199431063 in #4\n",
      "\t\t# 100 1.4889654503569059\n",
      "\t\t# 200 0.6869779663578637\n",
      "\t  - before:  22.75700199431063\n",
      "\t  - after (GD):  0.8468394864486928\n",
      "\t\n",
      "Initial Fitness: 14.119447291083956 in #5\n",
      "\t\t# 100 0.6775995900179203\n",
      "\t\t# 200 0.6775995900179203\n",
      "\t  - before:  14.119447291083956\n",
      "\t  - after (GD):  0.8051182759679122\n",
      "\t\n",
      "Initial Fitness: 21.476473008667032 in #6\n",
      "\t\t# 100 0.6732628737647298\n",
      "\t\t# 200 0.6732628737647298\n",
      "\t  - before:  21.476473008667032\n",
      "\t  - after (GD):  0.8153516543338458\n",
      "\t\n",
      "Initial Fitness: 17.178594680661647 in #7\n",
      "\t\t# 100 0.9258777705991473\n",
      "\t\t# 200 0.7089526974581566\n",
      "\t  - before:  17.178594680661647\n",
      "\t  - after (GD):  0.8712540862879019\n",
      "\t\n",
      "Initial Fitness: 18.975711735792693 in #8\n",
      "\t\t# 100 1.5691038317169945\n"
     ]
    }
   ],
   "source": [
    "# it = 80\n",
    "# n = 4\n",
    "def GD(GD_alph, iter, of_alpha):\n",
    "    startTime_GD = str(int(time.time()))\n",
    "    import numpy as np  \n",
    "    n = 100\n",
    "    sols = np.zeros((n, 2))\n",
    "    best, bestSol = 10, None\n",
    "    eTime = 0\n",
    "\n",
    "    print(f'\\n* Number of iterations: {iter}')\n",
    "    for i in range(n):\n",
    "        r = random_start(bounds)\n",
    "        fitness = objective_function(r, ShF, ShM, of_alpha)\n",
    "        print(f\"\\t\\nInitial Fitness: {fitness} in #{i}\")\n",
    "        start = time.perf_counter()\n",
    "        r = Gradient_Descent(r,objective_function, bounds,MaxIter=iter, alpha=GD_alph)\n",
    "        end = time.perf_counter()\n",
    "        fit_GD = objective_function(r,ShF,ShM, of_alpha)\n",
    "        print(\"\\t  - before: \", fitness)\n",
    "        print(\"\\t  - after (GD): \", fit_GD)\n",
    "        if fit_GD < best:\n",
    "            best = fit_GD\n",
    "            bestSol = r\n",
    "        eTime += (end-start) #Time in seconds\n",
    "        logSample(startTime_GD, r, fit_GD, ShF(r), ShM(r)) # (now, sample, fitness, force, moment):\n",
    "    if n: eTime /= n\n",
    "    print(\"Average time of execution:\", eTime,\"seconds. It was run\", n, \"times.\")\n",
    "    # return fit_GD\n",
    "\n",
    "it = 200\n",
    "of_alpha = np.random.normal(0.5, 0.20)\n",
    "print(GD(1e-3, it, of_alpha))\n",
    "print(GD(1e-5, it, of_alpha))\n",
    "print(GD(1e-8, it, of_alpha))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36d8014425df087c299dae688a2df59daa7f4b005992d2496cc7a95dceb622c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
